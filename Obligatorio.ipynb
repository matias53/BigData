{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimo la hubicacion de la variable de entorno JAVA_HOME\n",
    "\n",
    "Debe ser JAVA 64bits y la ruta no debe tener espacios ( Windows )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Progra~1\\Java\\jre1.8.0_271\n"
     ]
    }
   ],
   "source": [
    "echo %JAVA_HOME%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se configura pyspark para utilizar 20GB de RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "\n",
    "memory = '20g'\n",
    "pyspark_submit_args = ' --driver-memory ' + memory + ' pyspark-shell'\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = pyspark_submit_args\n",
    "\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, DateType, IntegerType, StringType, DoubleType, BooleanType\n",
    "from pyspark.sql.functions import datediff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = pyspark.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date – The date of the file in yyyy-mm-dd format.\n",
    "\n",
    "Serial Number – The manufacturer-assigned serial number of the drive.\n",
    "\n",
    "Model – The manufacturer-assigned model number of the drive.\n",
    "\n",
    "Capacity – The drive capacity in bytes.\n",
    "\n",
    "Failure – Contains a “0” if the drive is OK. Contains a “1” if this is the last day the drive was operational before failing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType() \\\n",
    "      .add(\"Date\", DateType(),True) \\\n",
    "      .add(\"Serial_Number\",StringType(),True) \\\n",
    "      .add(\"Model\",StringType(),True) \\\n",
    "      .add(\"capacity_bytes\",DoubleType(),True) \\\n",
    "      .add(\"Failure\",IntegerType(),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia = sqlContext.read.options(header='True', delimiter=',') \\\n",
    "        .schema(schema) \\\n",
    "        .csv(\"../bigdata/**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Serial_Number: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- capacity_bytes: double (nullable = true)\n",
      " |-- Failure: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dia.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia.registerTempTable(\"diskData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-----------+\n",
      "|database|tableName|isTemporary|\n",
      "+--------+---------+-----------+\n",
      "|        | diskdata|       true|\n",
      "+--------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total de discos Discos del Datacenter con su fecha de Puesta en funcionamiento y dia de retiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AllDisksDayInDayOut = sqlContext.sql('Select Serial_Number, Model, Min(Date) as DayIn, Max(Date) as DayOut, Count(1) as Count from diskData group by Serial_Number, Model order by Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AllDisksDayInDayOut.createOrReplaceTempView('tbl_AllDisksDayInDayOut')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agrega nueva tabla tbl_AllDisksDayInDayOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "|        |            diskdata|       true|\n",
      "|        |tbl_alldisksdayin...|       true|\n",
      "+--------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('show tables').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esquema de tabla tbl_AllDisksDayInDayOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Serial_Number: string (nullable = true)\n",
      " |-- Model: string (nullable = true)\n",
      " |-- DayIn: date (nullable = true)\n",
      " |-- DayOut: date (nullable = true)\n",
      " |-- Count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_AllDisksDayInDayOut.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de discos por modelo que existen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql('Select Model, Count(1) as Count from tbl_AllDisksDayInDayOut group by Model order by Count desc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listar la cantidad promedio de días que un dura un disco duro en operacion según su modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql('Select CAST(AVG(DATEDIFF(DayOut, DayIn)) AS DECIMAL(10,2)) as Days, Model from tbl_AllDisksDayInDayOut Group by Model order by Days desc').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql('Select Count(1) as Cuenta, Model from diskData group by Model, Serial_Number order by Cuenta desc').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql('Select Count(1) as Cuenta, Model from diskData group by Model, Serial_Number order by Cuenta desc')\\\n",
    "          .repartition(1)\\\n",
    "          .write.format(\"parquet\")\\\n",
    "          .save(\"output/parquet/transacciones\", mode=\"OVERWRITE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_averagedia.createOrReplaceTempView('tblAverageDia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cantidad de TB en el Datacenter por modelo de disco duro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               Model|         TB|\n",
      "+--------------------+-----------+\n",
      "|HGST HMS5C4040BLE640|83827074.69|\n",
      "|HGST HUH721212ALN604|64281208.75|\n",
      "|       ST12000NM0008|42626846.54|\n",
      "| TOSHIBA MG07ACA14TA|37967657.99|\n",
      "|HGST HMS5C4040ALE640|37739576.47|\n",
      "|Hitachi HDS5C3030...|18124970.05|\n",
      "|         ST6000DX000|17138601.81|\n",
      "|Hitachi HDS5C4040...|16017770.17|\n",
      "|       ST10000NM0086|12121416.06|\n",
      "|HGST HUH721212ALE600| 9911802.31|\n",
      "|Hitachi HDS722020...| 9654412.63|\n",
      "|HGST HUH728080ALE600| 7785900.79|\n",
      "|       ST12000NM001G| 7482419.31|\n",
      "|         ST3000DM001| 6017900.54|\n",
      "|Hitachi HDS723030...| 3901592.00|\n",
      "|        WDC WD60EFRX| 3743580.24|\n",
      "|        WDC WD30EFRX| 3470687.38|\n",
      "|        ST31500541AS| 1972022.64|\n",
      "|         ST4000DX000| 1068175.19|\n",
      "| TOSHIBA MD04ABA400V|  951620.52|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select Model, CAST(SUM(capacity_bytes/1099511627776) AS DECIMAL(10,2)) as TB from diskData group by model order by TB desc').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 modeos de discos más confiables por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql('').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 modeos de discos más confiables por año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.sql('').show(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cantidad de discos que fallaron por año vs discos en el data center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|Failures|Year|\n",
      "+--------+----+\n",
      "|     740|2013|\n",
      "|    2206|2014|\n",
      "|    1429|2015|\n",
      "|    1431|2016|\n",
      "|    1556|2017|\n",
      "|    1381|2018|\n",
      "|    2263|2019|\n",
      "|    1093|2020|\n",
      "+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select Count(Failure) as Failures, Year(Date) as Year from diskData where Failure = 1 group by year(Date) order by Year').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+----+\n",
      "|count(DISTINCT Serial_Number)|Year|\n",
      "+-----------------------------+----+\n",
      "|                       124326|2018|\n",
      "|                        62898|2015|\n",
      "|                        29072|2013|\n",
      "|                        47793|2014|\n",
      "|                       136568|2019|\n",
      "|                       162997|2020|\n",
      "|                        81173|2016|\n",
      "|                       108282|2017|\n",
      "+-----------------------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('select count(distinct Serial_Number) as Count, Year(Date) as Year from diskData group by Year(date)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----+\n",
      "| Count|Failures|Year|\n",
      "+------+--------+----+\n",
      "| 29072|     740|2013|\n",
      "| 47793|    2206|2014|\n",
      "| 62898|    1429|2015|\n",
      "| 81173|    1431|2016|\n",
      "|108282|    1556|2017|\n",
      "|124326|    1381|2018|\n",
      "|136568|    2263|2019|\n",
      "|162997|    1093|2020|\n",
      "+------+--------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.sql('Select Count, Failures, Failures.Year from (select count(distinct Serial_Number) as Count, Year(Date) as Year from diskData group by Year(date)) as Disks inner Join (select Count(Failure) as Failures, Year(Date) as Year from diskData where Failure = 1 group by year(Date) order by Year) as Failures on Disks.Year = Failures.Year order by Failures.Year').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedData = dia.select(\"Date\", \"Serial_Number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedData.write.csv('test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
